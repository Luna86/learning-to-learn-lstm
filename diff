diff --git a/.gitignore b/.gitignore
deleted file mode 100644
index 80a36f5..0000000
--- a/.gitignore
+++ /dev/null
@@ -1,2 +0,0 @@
-results/*
-*.pyc
diff --git a/evaluate.py b/evaluate.py
index 956a5de..2d9d86e 100644
--- a/evaluate.py
+++ b/evaluate.py
@@ -25,8 +25,6 @@ from tensorflow.contrib.learn.python.learn import monitored_session as ms
 
 import meta
 import util
-import numpy as np
-import os
 
 flags = tf.flags
 logging = tf.logging
@@ -35,7 +33,7 @@ logging = tf.logging
 FLAGS = flags.FLAGS
 flags.DEFINE_string("optimizer", "L2L", "Optimizer.")
 flags.DEFINE_string("path", None, "Path to saved meta-optimizer network.")
-flags.DEFINE_integer("num_epochs", 1, "Number of evaluation epochs.")
+flags.DEFINE_integer("num_epochs", 100, "Number of evaluation epochs.")
 flags.DEFINE_integer("seed", None, "Seed for TensorFlow's RNG.")
 
 flags.DEFINE_string("problem", "simple", "Type of problem.")
@@ -60,63 +58,17 @@ def main(_):
     cost_op = problem()
     problem_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)
     problem_reset = tf.variables_initializer(problem_vars)
-    x_op = problem_vars
 
     optimizer = tf.train.AdamOptimizer(FLAGS.learning_rate)
     optimizer_reset = tf.variables_initializer(optimizer.get_slot_names())
     update = optimizer.minimize(cost_op)
     reset = [problem_reset, optimizer_reset]
-
-  elif FLAGS.optimizer == "SGD":
-    cost_op = problem()
-    problem_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)
-    problem_reset = tf.variables_initializer(problem_vars)
-    x_op = problem_vars
-
-    optimizer = tf.train.GradientDescentOptimizer(FLAGS.learning_rate)
-    optimizer_reset = tf.variables_initializer(optimizer.get_slot_names())
-    update = optimizer.minimize(cost_op)
-    reset = [problem_reset, optimizer_reset]
-
-  elif FLAGS.optimizer == "RMSProp":
-    cost_op = problem()
-    problem_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)
-    problem_reset = tf.variables_initializer(problem_vars)
-    x_op = problem_vars
-
-    optimizer = tf.train.RMSPropOptimizer(FLAGS.learning_rate)
-    optimizer_reset = tf.variables_initializer(optimizer.get_slot_names())
-    update = optimizer.minimize(cost_op)
-    reset = [problem_reset, optimizer_reset]
-
-  elif FLAGS.optimizer == "Momentum":
-    cost_op = problem()
-    problem_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)
-    problem_reset = tf.variables_initializer(problem_vars)
-    x_op = problem_vars
-
-    optimizer = tf.train.MomentumOptimizer(FLAGS.learning_rate, momentum=0.1)
-    optimizer_reset = tf.variables_initializer(optimizer.get_slot_names())
-    update = optimizer.minimize(cost_op)
-    reset = [problem_reset, optimizer_reset]
-
-  elif FLAGS.optimizer == "NAG":
-    cost_op = problem()
-    problem_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)
-    problem_reset = tf.variables_initializer(problem_vars)
-    x_op = problem_vars
-
-    optimizer = tf.train.MomentumOptimizer(FLAGS.learning_rate, momentum=0.1, use_nesterov=True)
-    optimizer_reset = tf.variables_initializer(optimizer.get_slot_names())
-    update = optimizer.minimize(cost_op)
-    reset = [problem_reset, optimizer_reset]
- 
   elif FLAGS.optimizer == "L2L":
     if FLAGS.path is None:
       logging.warning("Evaluating untrained L2L optimizer")
     optimizer = meta.MetaOptimizer(**net_config)
     meta_loss = optimizer.meta_loss(problem, 1, net_assignments=net_assignments)
-    _, update, reset, cost_op, x_op = meta_loss
+    _, update, reset, cost_op, _ = meta_loss
   else:
     raise ValueError("{} is not a valid optimizer".format(FLAGS.optimizer))
 
@@ -128,15 +80,11 @@ def main(_):
     total_cost = 0
     for _ in xrange(FLAGS.num_epochs):
       # Training.
-      time, cost, x_values = util.run_epoch(sess, cost_op, x_op, [update], reset,
+      time, cost = util.run_epoch(sess, cost_op, [update], reset,
                                   num_unrolls)
       total_time += time
       total_cost += cost
 
-    x_values = np.squeeze(x_values)
-    print ("x_values shape: {}".format(x_values.shape))
-    print ("x_values: {}".format(x_values))
-    np.savetxt(os.path.join('results', '{}.txt'.format(FLAGS.optimizer)), x_values, fmt='%f')
     # Results.
     util.print_stats("Epoch {}".format(FLAGS.num_epochs), total_cost,
                      total_time, FLAGS.num_epochs)
diff --git a/evaluate_old.py b/evaluate_old.py
deleted file mode 100644
index 2d9d86e..0000000
--- a/evaluate_old.py
+++ /dev/null
@@ -1,94 +0,0 @@
-# Copyright 2016 Google Inc.
-#
-# Licensed under the Apache License, Version 2.0 (the "License");
-# you may not use this file except in compliance with the License.
-# You may obtain a copy of the License at
-#
-#     http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-# ==============================================================================
-"""Learning 2 Learn evaluation."""
-
-from __future__ import absolute_import
-from __future__ import division
-from __future__ import print_function
-
-from six.moves import xrange
-import tensorflow as tf
-
-from tensorflow.contrib.learn.python.learn import monitored_session as ms
-
-import meta
-import util
-
-flags = tf.flags
-logging = tf.logging
-
-
-FLAGS = flags.FLAGS
-flags.DEFINE_string("optimizer", "L2L", "Optimizer.")
-flags.DEFINE_string("path", None, "Path to saved meta-optimizer network.")
-flags.DEFINE_integer("num_epochs", 100, "Number of evaluation epochs.")
-flags.DEFINE_integer("seed", None, "Seed for TensorFlow's RNG.")
-
-flags.DEFINE_string("problem", "simple", "Type of problem.")
-flags.DEFINE_integer("num_steps", 100,
-                     "Number of optimization steps per epoch.")
-flags.DEFINE_float("learning_rate", 0.001, "Learning rate.")
-
-
-def main(_):
-  # Configuration.
-  num_unrolls = FLAGS.num_steps
-
-  if FLAGS.seed:
-    tf.set_random_seed(FLAGS.seed)
-
-  # Problem.
-  problem, net_config, net_assignments = util.get_config(FLAGS.problem,
-                                                         FLAGS.path)
-
-  # Optimizer setup.
-  if FLAGS.optimizer == "Adam":
-    cost_op = problem()
-    problem_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)
-    problem_reset = tf.variables_initializer(problem_vars)
-
-    optimizer = tf.train.AdamOptimizer(FLAGS.learning_rate)
-    optimizer_reset = tf.variables_initializer(optimizer.get_slot_names())
-    update = optimizer.minimize(cost_op)
-    reset = [problem_reset, optimizer_reset]
-  elif FLAGS.optimizer == "L2L":
-    if FLAGS.path is None:
-      logging.warning("Evaluating untrained L2L optimizer")
-    optimizer = meta.MetaOptimizer(**net_config)
-    meta_loss = optimizer.meta_loss(problem, 1, net_assignments=net_assignments)
-    _, update, reset, cost_op, _ = meta_loss
-  else:
-    raise ValueError("{} is not a valid optimizer".format(FLAGS.optimizer))
-
-  with ms.MonitoredSession() as sess:
-    # Prevent accidental changes to the graph.
-    tf.get_default_graph().finalize()
-
-    total_time = 0
-    total_cost = 0
-    for _ in xrange(FLAGS.num_epochs):
-      # Training.
-      time, cost = util.run_epoch(sess, cost_op, [update], reset,
-                                  num_unrolls)
-      total_time += time
-      total_cost += cost
-
-    # Results.
-    util.print_stats("Epoch {}".format(FLAGS.num_epochs), total_cost,
-                     total_time, FLAGS.num_epochs)
-
-
-if __name__ == "__main__":
-  tf.app.run()
diff --git a/problems.py b/problems.py
index cc29a3e..553556f 100644
--- a/problems.py
+++ b/problems.py
@@ -26,7 +26,6 @@ from six.moves import urllib
 from six.moves import xrange  # pylint: disable=redefined-builtin
 import sonnet as snt
 import tensorflow as tf
-import numpy as np
 
 from tensorflow.contrib.learn.python.learn.datasets import mnist as mnist_dataset
 
@@ -46,8 +45,7 @@ def simple():
         "x",
         shape=[],
         dtype=tf.float32,
-        initializer=tf.random_normal_initializer(mean=20000, stddev=0.01))
-    #initializer=tf.ones_initializer())
+        initializer=tf.ones_initializer())
     return tf.square(x, name="x_squared")
 
   return build
@@ -70,8 +68,7 @@ def simple_multi_optimizer(num_dims=2):
   return build
 
 
-#def quadratic(batch_size=128, num_dims=10, stddev=0.01, dtype=tf.float32):
-def quadratic(batch_size=1, num_dims=10, stddev=0.01, dtype=tf.float32):
+def quadratic(batch_size=128, num_dims=10, stddev=0.01, dtype=tf.float32):
   """Quadratic problem: f(x) = ||Wx - y||."""
 
   def build():
@@ -88,12 +85,12 @@ def quadratic(batch_size=1, num_dims=10, stddev=0.01, dtype=tf.float32):
     w = tf.get_variable("w",
                         shape=[batch_size, num_dims, num_dims],
                         dtype=dtype,
-                        initializer=tf.constant_initializer(np.array([[0.4, 0.6], [0.6, 0.5]])),
+                        initializer=tf.random_uniform_initializer(),
                         trainable=False)
     y = tf.get_variable("y",
                         shape=[batch_size, num_dims],
                         dtype=dtype,
-                        initializer=tf.constant_initializer(np.array([0.1, 0.9])),
+                        initializer=tf.random_uniform_initializer(),
                         trainable=False)
 
     product = tf.squeeze(tf.matmul(w, tf.expand_dims(x, -1)))
diff --git a/quadratic/cw.l2l b/quadratic/cw.l2l
deleted file mode 100644
index b1df9c8..0000000
Binary files a/quadratic/cw.l2l and /dev/null differ
diff --git a/quadratic2/cw.l2l b/quadratic2/cw.l2l
deleted file mode 100644
index f48f9f7..0000000
Binary files a/quadratic2/cw.l2l and /dev/null differ
diff --git a/simple-multi/adam.l2l b/simple-multi/adam.l2l
deleted file mode 100644
index 9c3b7fb..0000000
Binary files a/simple-multi/adam.l2l and /dev/null differ
diff --git a/simple-multi/cw.l2l b/simple-multi/cw.l2l
deleted file mode 100644
index 0428cb9..0000000
Binary files a/simple-multi/cw.l2l and /dev/null differ
diff --git a/simple/cw.l2l b/simple/cw.l2l
deleted file mode 100644
index 8402cc7..0000000
Binary files a/simple/cw.l2l and /dev/null differ
diff --git a/util.py b/util.py
index 315836e..49b38c7 100644
--- a/util.py
+++ b/util.py
@@ -27,23 +27,19 @@ from six.moves import xrange
 import problems
 
 
-def run_epoch(sess, cost_op, x_op, ops, reset, num_unrolls):
+def run_epoch(sess, cost_op, ops, reset, num_unrolls):
   """Runs one optimization epoch."""
   start = timer()
   sess.run(reset)
-  x_value_list = []
   for _ in xrange(num_unrolls):
-    cost, x_value = sess.run([cost_op, x_op] + ops)[0:2]
-    x_value_list.append(x_value)
-  x_values = np.array(x_value_list)
-  return timer() - start, cost, x_values
+    cost = sess.run([cost_op] + ops)[0]
+  return timer() - start, cost
 
 
 def print_stats(header, total_error, total_time, n):
   """Prints experiment statistics."""
   print(header)
-  print("Mean Final Error: {:.2f}".format(total_error / n))
-  #print("Log Mean Final Error: {:.2f}".format(np.log10(total_error / n)))
+  print("Log Mean Final Error: {:.2f}".format(np.log10(total_error / n)))
   print("Mean epoch time: {:.2f} s".format(total_time / n))
 
 
@@ -89,7 +85,7 @@ def get_config(problem_name, path=None):
     }
     net_assignments = [("cw", ["x_0"]), ("adam", ["x_1"])]
   elif problem_name == "quadratic":
-    problem = problems.quadratic(batch_size=1, num_dims=2)
+    problem = problems.quadratic(batch_size=128, num_dims=10)
     net_config = {"cw": {
         "net": "CoordinateWiseDeepLSTM",
         "net_options": {"layers": (20, 20)},
